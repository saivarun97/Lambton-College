{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.6.6","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# Handling Missing Values in Python\n","metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0"}},{"cell_type":"code","source":"import os\nimport pandas as pd\nimport numpy as np\n\nimport matplotlib.pyplot as plt\n%matplotlib inline\nimport seaborn as sns\n\nfrom sklearn import preprocessing\nfrom sklearn.model_selection import train_test_split, cross_val_score, StratifiedKFold\nfrom sklearn.linear_model import LogisticRegression\n\nimport missingno as msno","metadata":{"_kg_hide-input":true,"execution":{"iopub.status.busy":"2022-03-07T00:51:06.289534Z","iopub.execute_input":"2022-03-07T00:51:06.290088Z","iopub.status.idle":"2022-03-07T00:51:08.173508Z","shell.execute_reply.started":"2022-03-07T00:51:06.290040Z","shell.execute_reply":"2022-03-07T00:51:08.172548Z"},"trusted":true},"execution_count":1,"outputs":[]},{"cell_type":"markdown","source":"## Reading in the dataset\n* Reading in the Titanic Dataset.","metadata":{}},{"cell_type":"code","source":"os.listdir('../input/titanic')","metadata":{"execution":{"iopub.status.busy":"2022-03-07T00:51:08.175701Z","iopub.execute_input":"2022-03-07T00:51:08.176027Z","iopub.status.idle":"2022-03-07T00:51:08.185086Z","shell.execute_reply.started":"2022-03-07T00:51:08.175998Z","shell.execute_reply":"2022-03-07T00:51:08.184422Z"},"trusted":true},"execution_count":2,"outputs":[]},{"cell_type":"code","source":"train=pd.read_csv('../input/titanic/train.csv')\ntest=pd.read_csv('../input/titanic/test.csv')\n\nprint('Training data shape: ', train.shape)\nprint('Testing data shape: ', test.shape)\n\n# First few rows of the training dataset\ntrain.head()\n","metadata":{"execution":{"iopub.status.busy":"2022-03-07T00:51:08.188519Z","iopub.execute_input":"2022-03-07T00:51:08.189031Z","iopub.status.idle":"2022-03-07T00:51:08.256225Z","shell.execute_reply.started":"2022-03-07T00:51:08.188983Z","shell.execute_reply":"2022-03-07T00:51:08.255417Z"},"trusted":true},"execution_count":3,"outputs":[]},{"cell_type":"markdown","source":"## Examining the Target column \n\n>For each passenger in the test set, we need to create a model that predicts whether or not the passengers survived the sinking of the Titanic. Hence Survived is that target column in the dataset. Let's examine the Distribution of the target column","metadata":{}},{"cell_type":"code","source":" \ntrain['Survived'].value_counts()","metadata":{"execution":{"iopub.status.busy":"2022-03-07T00:51:08.260103Z","iopub.execute_input":"2022-03-07T00:51:08.260380Z","iopub.status.idle":"2022-03-07T00:51:08.274603Z","shell.execute_reply.started":"2022-03-07T00:51:08.260344Z","shell.execute_reply":"2022-03-07T00:51:08.273344Z"},"trusted":true},"execution_count":4,"outputs":[]},{"cell_type":"code","source":"s = sns.countplot(x = 'Survived',data = train)\nsizes=[]\nfor p in s.patches:\n    height = p.get_height()\n    sizes.append(height)\n    s.text(p.get_x()+p.get_width()/2.,\n            height + 3,\n            '{:1.2f}%'.format(height/len(train)*100),\n            ha=\"center\", fontsize=14) ","metadata":{"_kg_hide-input":true,"execution":{"iopub.status.busy":"2022-03-07T00:51:08.278255Z","iopub.execute_input":"2022-03-07T00:51:08.278524Z","iopub.status.idle":"2022-03-07T00:51:08.437277Z","shell.execute_reply.started":"2022-03-07T00:51:08.278496Z","shell.execute_reply":"2022-03-07T00:51:08.436381Z"},"trusted":true},"execution_count":5,"outputs":[]},{"cell_type":"markdown","source":"Here:\n* 0: Did not Survive while \n* 1: Survived. \n\nClearly, less people survived the accident.","metadata":{}},{"cell_type":"markdown","source":">Since the focus of the notebook is to detect and handle missing values, we'll jump directly into it. Let's now look at a step by step process to manage the missing values in a dataset.\n<hr>","metadata":{"trusted":true}},{"cell_type":"markdown","source":"# Detecting Missing values\n\n## Detecting missing values numerically \n\n>The first step is to detect the count/percentage of missing values in every column of the dataset. This will give an idea about the distribution of missing values.","metadata":{}},{"cell_type":"code","source":"# credit: https://www.kaggle.com/willkoehrsen/start-here-a-gentle-introduction. \n# One of the best notebooks on getting started with a ML problem.\n\ndef missing_values_table(df):\n        # Total missing values\n        mis_val = df.isnull().sum()\n        \n        # Percentage of missing values\n        mis_val_percent = 100 * df.isnull().sum() / len(df)\n        \n        # Make a table with the results\n        mis_val_table = pd.concat([mis_val, mis_val_percent], axis=1)\n        \n        # Rename the columns\n        mis_val_table_ren_columns = mis_val_table.rename(\n        columns = {0 : 'Missing Values', 1 : '% of Total Values'})\n        \n        # Sort the table by percentage of missing descending\n        mis_val_table_ren_columns = mis_val_table_ren_columns[\n            mis_val_table_ren_columns.iloc[:,1] != 0].sort_values(\n        '% of Total Values', ascending=False).round(1)\n        \n        # Print some summary information\n        print (\"Your selected dataframe has \" + str(df.shape[1]) + \" columns.\\n\"      \n            \"There are \" + str(mis_val_table_ren_columns.shape[0]) +\n              \" columns that have missing values.\")\n        \n        # Return the dataframe with missing information\n        return mis_val_table_ren_columns\n\n","metadata":{"_kg_hide-input":true,"execution":{"iopub.status.busy":"2022-03-07T00:51:08.438608Z","iopub.execute_input":"2022-03-07T00:51:08.438879Z","iopub.status.idle":"2022-03-07T00:51:08.448630Z","shell.execute_reply.started":"2022-03-07T00:51:08.438843Z","shell.execute_reply":"2022-03-07T00:51:08.447660Z"},"trusted":true},"execution_count":6,"outputs":[]},{"cell_type":"code","source":"train_missing= missing_values_table(train)\ntrain_missing","metadata":{"execution":{"iopub.status.busy":"2022-03-07T00:51:08.450187Z","iopub.execute_input":"2022-03-07T00:51:08.450535Z","iopub.status.idle":"2022-03-07T00:51:08.613051Z","shell.execute_reply.started":"2022-03-07T00:51:08.450494Z","shell.execute_reply":"2022-03-07T00:51:08.612289Z"},"trusted":true},"execution_count":7,"outputs":[]},{"cell_type":"code","source":"test_missing= missing_values_table(test)\ntest_missing","metadata":{"execution":{"iopub.status.busy":"2022-03-07T00:51:08.614526Z","iopub.execute_input":"2022-03-07T00:51:08.614778Z","iopub.status.idle":"2022-03-07T00:51:08.634752Z","shell.execute_reply.started":"2022-03-07T00:51:08.614751Z","shell.execute_reply":"2022-03-07T00:51:08.633751Z"},"trusted":true},"execution_count":8,"outputs":[]},{"cell_type":"markdown","source":"Both the train and test set have the same proportion of the missing values. ","metadata":{}},{"cell_type":"markdown","source":"## Detecting missing data visually using Missingno library\n\n>To graphically analyse the missingness of the data, let's use a library called [Missingno](https://github.com/ResidentMario/missingno) It is a package for graphical analysis of missing values. To use this library, we need to import it as follows: `import missingno as msno`","metadata":{}},{"cell_type":"code","source":"msno.bar(train)","metadata":{"execution":{"iopub.status.busy":"2022-03-07T00:51:08.636595Z","iopub.execute_input":"2022-03-07T00:51:08.637017Z","iopub.status.idle":"2022-03-07T00:51:09.676514Z","shell.execute_reply.started":"2022-03-07T00:51:08.636981Z","shell.execute_reply":"2022-03-07T00:51:09.675612Z"},"trusted":true},"execution_count":9,"outputs":[]},{"cell_type":"markdown","source":">The bar chart above gives a quick graphical overview of the completeness of the dataset. We can see that Age, Cabin and embarked columns have missing values. Next,it would make sense to find out the locations of the missing data.","metadata":{}},{"cell_type":"markdown","source":"### Visualizing the locations of the missing data \n\n>The [msno.matrix](https://github.com/ResidentMario/missingno#matrix) nullity matrix is a data-dense display which lets you quickly visually pick out patterns in data completion.\n","metadata":{}},{"cell_type":"code","source":"msno.matrix(train)","metadata":{"execution":{"iopub.status.busy":"2022-03-07T00:51:09.677785Z","iopub.execute_input":"2022-03-07T00:51:09.678061Z","iopub.status.idle":"2022-03-07T00:51:10.144020Z","shell.execute_reply.started":"2022-03-07T00:51:09.678033Z","shell.execute_reply":"2022-03-07T00:51:10.143086Z"},"trusted":true},"execution_count":10,"outputs":[]},{"cell_type":"markdown","source":">* The plot appears blank(white) wherever there are missing values. For instance, in Embarked column there are only two instances of missing data, hence the two white lines.\n>\n>* The sparkline on the right gives an idea of the general shape of the completeness of the data and points out the row with the minimum nullities and the total number of columns in a given dataset, at the bottom.\n>\n>It is also possible to sample the dataset to pinpoint the exact location of the missing values. For instance let's check the first 100 rows.","metadata":{}},{"cell_type":"markdown","source":"# Reasons for Missing Values \n\n\n\n**1. Missing Completely at Random (MCAR) **\n\n>The missing values on a given variable (Y) are not associated with other variables in a given data set or with the variable (Y) itself. In other words, there is no particular reason for the missing values.\n\n**2. Missing at Random (MAR) **\n\n>MAR occurs when the missingness is not random, but where missingness can be fully accounted for by variables where there is complete information.\n\n**3. Missing Not at Random (MNAR) **\n>Missingness depends on unobserved data or the value of the missing data itself. \n\n*All definitions taken from Wikipedia: https://en.wikipedia.org/wiki/Missing_data*\n\n\n","metadata":{}},{"cell_type":"markdown","source":"## Finding reason for missing data using matrix plot ","metadata":{}},{"cell_type":"code","source":"msno.matrix(train)","metadata":{"execution":{"iopub.status.busy":"2022-03-07T00:51:10.541357Z","iopub.execute_input":"2022-03-07T00:51:10.541876Z","iopub.status.idle":"2022-03-07T00:51:10.928418Z","shell.execute_reply.started":"2022-03-07T00:51:10.541795Z","shell.execute_reply":"2022-03-07T00:51:10.927512Z"},"trusted":true},"execution_count":12,"outputs":[]},{"cell_type":"markdown","source":">* The `Embarked` Column has very few missing values and donot seem to be correlated with any other column, Hence, the missingness in Embarked column can be attributed as Missing Completely at Random.\n* Both the `Age` and the `Cabin` columns have a lot of missing values.This could be a case of MAR as we cannot directly observe the reason for missingness of data in these columns.\n\nThe missingno package also let's us sort the graph by a particluar column. Let's sort the values by `Age` and `Cabin` column to see if there is a pattern in the missing values","metadata":{}},{"cell_type":"code","source":"#sorted by Age\nsorted = train.sort_values('Age')\nmsno.matrix(sorted)","metadata":{"execution":{"iopub.status.busy":"2022-03-07T00:51:10.930024Z","iopub.execute_input":"2022-03-07T00:51:10.930593Z","iopub.status.idle":"2022-03-07T00:51:11.321808Z","shell.execute_reply.started":"2022-03-07T00:51:10.930546Z","shell.execute_reply":"2022-03-07T00:51:11.320898Z"},"trusted":true},"execution_count":13,"outputs":[]},{"cell_type":"markdown","source":"Hence it is clear that here is no relation between the missingness in Age and Cabin column.To cement this conclusion further we can also draw a Heatmap among the different variables in the dataset.","metadata":{}},{"cell_type":"markdown","source":"## Finding reason for missing data using a Heatmap ","metadata":{}},{"cell_type":"code","source":"msno.heatmap(train)","metadata":{"execution":{"iopub.status.busy":"2022-03-07T00:51:11.323560Z","iopub.execute_input":"2022-03-07T00:51:11.324206Z","iopub.status.idle":"2022-03-07T00:51:11.621240Z","shell.execute_reply.started":"2022-03-07T00:51:11.324164Z","shell.execute_reply":"2022-03-07T00:51:11.620302Z"},"trusted":true},"execution_count":14,"outputs":[]},{"cell_type":"markdown","source":"The heatmap function shows that there are no strong correlations between missing values of different features. This is good; low correlations further indicate that the data are MAR.","metadata":{}},{"cell_type":"markdown","source":"# Treating Missing values  \n\n","metadata":{}},{"cell_type":"code","source":"train.isnull().sum()","metadata":{"execution":{"iopub.status.busy":"2022-03-07T00:51:11.893397Z","iopub.execute_input":"2022-03-07T00:51:11.893901Z","iopub.status.idle":"2022-03-07T00:51:11.905683Z","shell.execute_reply.started":"2022-03-07T00:51:11.893859Z","shell.execute_reply":"2022-03-07T00:51:11.904753Z"},"trusted":true},"execution_count":16,"outputs":[]},{"cell_type":"code","source":"train_1 = train.copy()\ntrain_1['Age'].mean() #pandas skips the missing values and calculates mean of the remaining values.","metadata":{"execution":{"iopub.status.busy":"2022-03-07T00:51:11.907201Z","iopub.execute_input":"2022-03-07T00:51:11.907685Z","iopub.status.idle":"2022-03-07T00:51:11.916279Z","shell.execute_reply.started":"2022-03-07T00:51:11.907644Z","shell.execute_reply":"2022-03-07T00:51:11.915190Z"},"trusted":true},"execution_count":17,"outputs":[]},{"cell_type":"markdown","source":"\n### Listwise Deletion/ Dropping rows\n\n>During Listwise deletion, complete rows(which contain the missing values) are deleted. As a result, it is also called Complete Case deletion. Like Pairwise deletion, listwise deletions are also only used for MCAR values.\n","metadata":{}},{"cell_type":"code","source":"#Drop rows which contains any NaN or missing value for Age column\ntrain_1.dropna(subset=['Age'],how='any',inplace=True)\ntrain_1['Age'].isnull().sum()","metadata":{"execution":{"iopub.status.busy":"2022-03-07T00:51:11.917802Z","iopub.execute_input":"2022-03-07T00:51:11.918502Z","iopub.status.idle":"2022-03-07T00:51:11.933433Z","shell.execute_reply.started":"2022-03-07T00:51:11.918457Z","shell.execute_reply":"2022-03-07T00:51:11.932336Z"},"trusted":true},"execution_count":18,"outputs":[]},{"cell_type":"markdown","source":">The Age column doesn't have any missing values.A major diadvantage of Listwise deletion is that a major chunk of data and hence a lot of information is lost. Hence, it is advisable to use it only when the number of missing values is very small.","metadata":{}},{"cell_type":"markdown","source":"\n### Dropping complete columns \n\nIf a column contains a lot of missing values, say more than 80%, and the feature is not significant, you might want to delete that feature. However, again, it is not a good methodology to delete data.\n","metadata":{}},{"cell_type":"markdown","source":"## Imputations Techniques for non Time Series Problems \n\n\n### Basic Imputation Techniques\n  \n  - Imputating with a constant value\n  - Imputation using the statistics (mean, median or most frequent) of each column in which the missing values are located\n\nFor this we shall use the `The SimpleImputer` class from sklearn.","metadata":{"trusted":true}},{"cell_type":"code","source":"# imputing with a constant\n\nfrom sklearn.impute import SimpleImputer\ntrain_constant = train.copy()\n#setting strategy to 'constant' \nmean_imputer = SimpleImputer(strategy='constant') # imputing using constant value\ntrain_constant.iloc[:,:] = mean_imputer.fit_transform(train_constant)\ntrain_constant.isnull().sum()","metadata":{"execution":{"iopub.status.busy":"2022-03-07T00:51:11.935338Z","iopub.execute_input":"2022-03-07T00:51:11.935983Z","iopub.status.idle":"2022-03-07T00:51:12.034919Z","shell.execute_reply.started":"2022-03-07T00:51:11.935934Z","shell.execute_reply":"2022-03-07T00:51:12.033955Z"},"trusted":true},"execution_count":19,"outputs":[]},{"cell_type":"code","source":"from sklearn.impute import SimpleImputer\ntrain_most_frequent = train.copy()\n#setting strategy to 'mean' to impute by the mean\nmean_imputer = SimpleImputer(strategy='most_frequent')# strategy can also be mean or median \ntrain_most_frequent.iloc[:,:] = mean_imputer.fit_transform(train_most_frequent)","metadata":{"execution":{"iopub.status.busy":"2022-03-07T00:51:12.036626Z","iopub.execute_input":"2022-03-07T00:51:12.037267Z","iopub.status.idle":"2022-03-07T00:51:12.067964Z","shell.execute_reply.started":"2022-03-07T00:51:12.037221Z","shell.execute_reply":"2022-03-07T00:51:12.067136Z"},"trusted":true},"execution_count":20,"outputs":[]},{"cell_type":"code","source":"train_most_frequent.isnull().sum()","metadata":{"execution":{"iopub.status.busy":"2022-03-07T00:51:12.069587Z","iopub.execute_input":"2022-03-07T00:51:12.071061Z","iopub.status.idle":"2022-03-07T00:51:12.081531Z","shell.execute_reply.started":"2022-03-07T00:51:12.071011Z","shell.execute_reply":"2022-03-07T00:51:12.080453Z"},"trusted":true},"execution_count":21,"outputs":[]},{"cell_type":"markdown","source":"## Imputations Techniques for Time Series Problems\n\nNow let's look at ways to impute data in a typical time series problem. Tackling missing values in time Series problem is a bit different. The `fillna()` method is used for imputing missing values in such problems.\n\n* Basic Imputation Techniques\n  - 'ffill' or 'pad' - Replace NaN s with last observed value\n  - 'bfill' or 'backfill' - Replace NaN s with next observed value\n  -  Linear interpolation method\n\n### Time Series dataset\n\nThe dataset is called [Air Quality Data in India (2015 - 2020)](https://www.kaggle.com/rohanrao/air-quality-data-in-india) Tand it contains air quality data and AQI (Air Quality Index) at hourly and daily level of various stations across multiple cities in India.The dataset has a lot of missing values and and is a classic Time series problem.","metadata":{"trusted":true}},{"cell_type":"code","source":"os.listdir('../input/air-quality-data-in-india')","metadata":{"execution":{"iopub.status.busy":"2022-03-07T00:51:12.083100Z","iopub.execute_input":"2022-03-07T00:51:12.083446Z","iopub.status.idle":"2022-03-07T00:51:12.098489Z","shell.execute_reply.started":"2022-03-07T00:51:12.083413Z","shell.execute_reply":"2022-03-07T00:51:12.097602Z"},"trusted":true},"execution_count":22,"outputs":[]},{"cell_type":"code","source":"city_day = pd.read_csv('../input/air-quality-data-in-india/city_day.csv',parse_dates=True,index_col='Date')\ncity_day1=city_day.copy(deep=True)\ncity_day.head()","metadata":{"execution":{"iopub.status.busy":"2022-03-07T00:51:12.100008Z","iopub.execute_input":"2022-03-07T00:51:12.100315Z","iopub.status.idle":"2022-03-07T00:51:12.243379Z","shell.execute_reply.started":"2022-03-07T00:51:12.100284Z","shell.execute_reply":"2022-03-07T00:51:12.242436Z"},"trusted":true},"execution_count":23,"outputs":[]},{"cell_type":"markdown","source":"I won't go much into explaining the data since I have done a lot of relatedw work in my kernel titled [ðŸ˜· Breathe India: COVID-19 effect on Pollution](https://www.kaggle.com/parulpandey/breathe-india-covid-19-effect-on-pollution).In this notebook, let's keep our focus on the missing values only. As id evident, city_day dataframe consists of daily pollution level data of some of the prominent cities in India.\n\n","metadata":{}},{"cell_type":"code","source":"#Missing Values\ncity_day_missing= missing_values_table(city_day)\ncity_day_missing","metadata":{"execution":{"iopub.status.busy":"2022-03-07T00:51:12.244681Z","iopub.execute_input":"2022-03-07T00:51:12.244957Z","iopub.status.idle":"2022-03-07T00:51:12.279362Z","shell.execute_reply.started":"2022-03-07T00:51:12.244929Z","shell.execute_reply":"2022-03-07T00:51:12.278361Z"},"trusted":true},"execution_count":24,"outputs":[]},{"cell_type":"markdown","source":"There are a lot of missing values and some of the columns like Xylene and PM10 have more than 50% of the values missing. Let's now see how we can impute these missing values.\n\n","metadata":{}},{"cell_type":"code","source":"# Imputation using ffill/pad\n# Imputing Xylene value\n\ncity_day['Xylene'][50:64]\n","metadata":{"execution":{"iopub.status.busy":"2022-03-07T00:51:12.281019Z","iopub.execute_input":"2022-03-07T00:51:12.281375Z","iopub.status.idle":"2022-03-07T00:51:12.289679Z","shell.execute_reply.started":"2022-03-07T00:51:12.281332Z","shell.execute_reply":"2022-03-07T00:51:12.288965Z"},"trusted":true},"execution_count":25,"outputs":[]},{"cell_type":"markdown","source":"Above we see, there are 3 missing values in the Xylene column. \n\n### Imputing using ffill","metadata":{}},{"cell_type":"code","source":"city_day.fillna(method='ffill',inplace=True)\ncity_day['Xylene'][50:65]","metadata":{"execution":{"iopub.status.busy":"2022-03-07T00:51:12.291016Z","iopub.execute_input":"2022-03-07T00:51:12.291467Z","iopub.status.idle":"2022-03-07T00:51:12.313986Z","shell.execute_reply.started":"2022-03-07T00:51:12.291426Z","shell.execute_reply":"2022-03-07T00:51:12.313113Z"},"trusted":true},"execution_count":26,"outputs":[]},{"cell_type":"markdown","source":"We can see that all missing values have been filled with the last observed values.\n\n### Imputation using bfill","metadata":{}},{"cell_type":"code","source":"# Imputing AQI value\n\ncity_day['AQI'][20:30]","metadata":{"execution":{"iopub.status.busy":"2022-03-07T00:51:12.315313Z","iopub.execute_input":"2022-03-07T00:51:12.315560Z","iopub.status.idle":"2022-03-07T00:51:12.322781Z","shell.execute_reply.started":"2022-03-07T00:51:12.315534Z","shell.execute_reply":"2022-03-07T00:51:12.321957Z"},"trusted":true},"execution_count":27,"outputs":[]},{"cell_type":"code","source":"city_day.fillna(method='bfill',inplace=True)\ncity_day['AQI'][20:30]","metadata":{"execution":{"iopub.status.busy":"2022-03-07T00:51:12.324165Z","iopub.execute_input":"2022-03-07T00:51:12.324512Z","iopub.status.idle":"2022-03-07T00:51:12.345974Z","shell.execute_reply.started":"2022-03-07T00:51:12.324485Z","shell.execute_reply":"2022-03-07T00:51:12.344962Z"},"trusted":true},"execution_count":28,"outputs":[]},{"cell_type":"markdown","source":"We can see that all missing values have been filled with the next observed values.","metadata":{}},{"cell_type":"markdown","source":"### Imputation using Linear Interpolation method\n\nTime series data has a lot of variations against time. Hence, imputing using backfill and forward fill isn't the ebst possible solution to address the missing value problem. A more apt alternative would be to use interpolation methods, where the values are filled with incrementing or decrementing values.\n\n[Linear interpolation](https://www.lexjansen.com/nesug/nesug01/ps/ps8026.pdf) is an imputation technique that assumes a linear relationship between data points and utilises non-missing values from adjacent data points to compute a value for a missing data point. \n\nRefer to the official documentation for a complete list of interpolation strategies [here](https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.interpolate.html)","metadata":{}},{"cell_type":"code","source":"city_day1['Xylene'][50:65]","metadata":{"execution":{"iopub.status.busy":"2022-03-07T00:51:12.347301Z","iopub.execute_input":"2022-03-07T00:51:12.347545Z","iopub.status.idle":"2022-03-07T00:51:12.355620Z","shell.execute_reply.started":"2022-03-07T00:51:12.347518Z","shell.execute_reply":"2022-03-07T00:51:12.354945Z"},"trusted":true},"execution_count":29,"outputs":[]},{"cell_type":"code","source":"# Interpolate using the linear method\ncity_day1.interpolate(limit_direction=\"both\",inplace=True)\ncity_day1['Xylene'][50:65]","metadata":{"execution":{"iopub.status.busy":"2022-03-07T00:51:12.356909Z","iopub.execute_input":"2022-03-07T00:51:12.357271Z","iopub.status.idle":"2022-03-07T00:51:14.939211Z","shell.execute_reply.started":"2022-03-07T00:51:12.357242Z","shell.execute_reply":"2022-03-07T00:51:14.938319Z"},"trusted":true},"execution_count":30,"outputs":[]},{"cell_type":"markdown","source":"## Advanced Imputation Techniques \n\nAdvanced imputation techniques uses machine learning algorithms to impute the missing values in a dataset unlike the previous techniques where we used other column values to predict the missing values. We shall look at the following two techniques in this notebook:\n\n* [Nearest neighbors imputation](https://scikit-learn.org/stable/modules/impute.html#nearest-neighbors-imputation)\n* [Multivariate feature imputation](https://scikit-learn.org/stable/modules/impute.html#multivariate-feature-imputation)\n\n### K-Nearest Neighbor Imputation\n\nThe [KNNImputer class](https://scikit-learn.org/stable/modules/impute.html#multivariate-feature-imputation) provides imputation for filling in missing values using the k-Nearest Neighbors approach.Each missing feature is imputed using values from n_neighbors nearest neighbors that have a value for the feature. The feature of the neighbors are averaged uniformly or weighted by distance to each neighbor. ","metadata":{}},{"cell_type":"code","source":"train_knn = train.copy(deep=True)","metadata":{"execution":{"iopub.status.busy":"2022-03-07T00:51:14.944803Z","iopub.execute_input":"2022-03-07T00:51:14.945220Z","iopub.status.idle":"2022-03-07T00:51:14.950876Z","shell.execute_reply.started":"2022-03-07T00:51:14.945173Z","shell.execute_reply":"2022-03-07T00:51:14.949788Z"},"trusted":true},"execution_count":31,"outputs":[]},{"cell_type":"code","source":"from sklearn.impute import KNNImputer\ntrain_knn = train.copy(deep=True)\n\nknn_imputer = KNNImputer(n_neighbors=2, weights=\"uniform\")\ntrain_knn['Age'] = knn_imputer.fit_transform(train_knn[['Age']])","metadata":{"execution":{"iopub.status.busy":"2022-03-07T00:51:14.952764Z","iopub.execute_input":"2022-03-07T00:51:14.953155Z","iopub.status.idle":"2022-03-07T00:51:14.976947Z","shell.execute_reply.started":"2022-03-07T00:51:14.953109Z","shell.execute_reply":"2022-03-07T00:51:14.975619Z"},"trusted":true},"execution_count":32,"outputs":[]},{"cell_type":"code","source":"train_knn['Age'].isnull().sum()\n","metadata":{"execution":{"iopub.status.busy":"2022-03-07T00:51:14.981114Z","iopub.execute_input":"2022-03-07T00:51:14.981719Z","iopub.status.idle":"2022-03-07T00:51:14.991238Z","shell.execute_reply.started":"2022-03-07T00:51:14.981667Z","shell.execute_reply":"2022-03-07T00:51:14.990052Z"},"trusted":true},"execution_count":33,"outputs":[]},{"cell_type":"markdown","source":"### Multivariate feature imputation - Multivariate imputation by chained equations (MICE)\nA strategy for imputing missing values by modeling each feature with missing values as a function of other features in a round-robin fashion. It performns multiple regressions over random sample ofthe data, then takes the average ofthe multiple regression values and uses that value to impute the missing value. In sklearn, it is implemented as follows:\n\n","metadata":{}},{"cell_type":"code","source":"from sklearn.experimental import enable_iterative_imputer\nfrom sklearn.impute import IterativeImputer\ntrain_mice = train.copy(deep=True)\n\nmice_imputer = IterativeImputer()\ntrain_mice['Age'] = mice_imputer.fit_transform(train_mice[['Age']])","metadata":{"execution":{"iopub.status.busy":"2022-03-07T00:51:14.993372Z","iopub.execute_input":"2022-03-07T00:51:14.994239Z","iopub.status.idle":"2022-03-07T00:51:15.013476Z","shell.execute_reply.started":"2022-03-07T00:51:14.994188Z","shell.execute_reply":"2022-03-07T00:51:15.012462Z"},"trusted":true},"execution_count":34,"outputs":[]},{"cell_type":"code","source":"train_mice['Age'].isnull().sum()","metadata":{"execution":{"iopub.status.busy":"2022-03-07T00:51:15.015080Z","iopub.execute_input":"2022-03-07T00:51:15.016040Z","iopub.status.idle":"2022-03-07T00:51:15.024348Z","shell.execute_reply.started":"2022-03-07T00:51:15.015991Z","shell.execute_reply":"2022-03-07T00:51:15.023443Z"},"trusted":true},"execution_count":35,"outputs":[]},{"cell_type":"markdown","source":"# Algorithms which handle missing values\n\nSome algprithms like XGBoost and LightGBM can handle missing values without any preprocessing, by supplying relevant parameters.\n\n# Conclusion\n\nWell, there is no single best way to handle missing values. One needs to experiment with different methods and then decide which method is best for a particular problem.","metadata":{}},{"cell_type":"markdown","source":"# References and good resources \n\n* [Dealing with Missing Data in Python](https://campus.datacamp.com/courses/dealing-with-missing-data-in-python/the-problem-with-missing-data?ex=1)\n* [How to Handle Missing Data](https://towardsdatascience.com/how-to-handle-missing-data-8646b18db0d4)","metadata":{}},{"cell_type":"code","source":"","metadata":{"trusted":true},"execution_count":null,"outputs":[]}]}